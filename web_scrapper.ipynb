{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgJc4V95MrIV",
        "outputId": "c7c5e362-2bf5-4866-bd50-0b7c0b5c40f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xbza9svXO3Yt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8-85b9xPA_B",
        "outputId": "adcde88d-7ad5-41ee-dae0-1ef758b57816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
            "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
            "  <link href=\"/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>\n",
            "  <script type=\"application/ld+json\">\n",
            "   {\n",
            " \"@context\": \"http://schema.org\",\n",
            " \"@type\": \"WebSite\",\n",
            " \"name\": \"FIFA Ratings\",\n",
            " \"url\": \"https://www.fifaratings.com\"\n",
            " }\n",
            "  </script>\n",
            "  <!-- Start Ad Network -->\n",
            "  <link crossorigin=\"\" href=\"https://a.pub.network/\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://b.pub.network/\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://c.pub.network/\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://d.pub.network/\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://c.amazon-adsystem.com\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://s.amazon-adsystem.com\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\"\" href=\"https://btloader.com/\" rel=\"preconnect\"/>\n",
            "  <link crossorigin=\n"
          ]
        }
      ],
      "source": [
        "# checking webpage can be accessed or not\n",
        "url = \"https://www.fifaratings.com\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    print(soup.prettify()[:1000])  # Preview first 1000 characters of HTML\n",
        "else:\n",
        "    print(\"Failed to fetch page. Status Code:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m7yvQG93T4UR"
      },
      "outputs": [],
      "source": [
        "# Define target URL\n",
        "url = \"https://www.fifaratings.com/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "# Fetch the webpage\n",
        "response = requests.get(url, headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJTcpLr1Q0SR",
        "outputId": "8546ba43-a620-41f8-8b20-16d72cb87a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page fetched successfully!\n",
            "Detected Headers: ['#', 'Player', 'OVA', 'TOTAL']\n",
            "âœ… Data saved successfully as 'ipl_2016_stats.csv'\n"
          ]
        }
      ],
      "source": [
        "# Check if the request was successfull\n",
        "if response.status_code == 200:\n",
        "    print(\"Page fetched successfully!\")\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Locate the table containing stats\n",
        "    table = soup.find(\"table\") \n",
        "    if not table:\n",
        "        print(\"No table found! Check website structure.\")\n",
        "    else:\n",
        "        # Extract table headers\n",
        "        headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
        "        print(\"Detected Headers:\", headers)\n",
        "\n",
        "        # Extract data from table rows\n",
        "        rows = table.find_all(\"tr\")[1:]  \n",
        "        data = []\n",
        "\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "            cols = [col.text.strip() for col in cols]\n",
        "\n",
        "            # Ensure correct number of columns\n",
        "            if len(cols) == len(headers):\n",
        "                data.append(cols)\n",
        "            else:\n",
        "                print(f\"Skipping row (unexpected columns): {cols}\")\n",
        "\n",
        "        # Create a DataFrame and save to CSV\n",
        "        if data:\n",
        "            df = pd.DataFrame(data, columns=headers)\n",
        "            df.to_csv(\"fifa_stats.csv\", index=False)\n",
        "            print(\"Data saved successfully as 'ipl_2016_stats.csv'\")\n",
        "        else:\n",
        "            print(\"No valid data extracted.\")\n",
        "else:\n",
        "    print(f\"Failed to fetch page. Status Code: {response.status_code}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
